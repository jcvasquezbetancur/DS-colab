{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-start.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPPb6C3iMABEzRWi5QttsIB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcvasquezbetancur/DS-colab/blob/master/pytorch_start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzuRtfHF69is",
        "colab_type": "text"
      },
      "source": [
        "# Key sources - Pytorch Warm up \n",
        "* [Introduction and comparison](https://blog.paperspace.com/why-use-pytorch-deep-learning-framework/): with a linear regresion notebook.\n",
        "\n",
        "* [60 min beginner video-tutorial](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) by pytorch.org\n",
        "\n",
        "* [Learning examples](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html) by pytorch.org\n",
        "* [New free book: DL with pytorch](https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf)\n",
        "\n",
        "* [Tutorial at Scipy2020-July](https://github.com/hugobowne/deep-learning-from-scratch-pytorch): notebooks at github.\n",
        "\n",
        "* [Tensorboard tutorial](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)Visualize models, data, results.\n",
        "\n",
        "* [Fast-ai Vid-notebook course](https://course.fast.ai/videos/?lesson=7) \n",
        "\n",
        "* [Mnist example](https://github.com/pytorch/examples/blob/master/mnist/main.py) at official git-repo.\n",
        "* [VAE example](https://github.com/pytorch/examples/tree/master/vae) at official git-repo.\n",
        "\n",
        "* Hand-ons enabling [GPU-pytorch](https://towardsdatascience.com/speed-up-your-algorithms-part-1-pytorch-56d8a4ae7051) acceleration/configuration \n",
        "* ComputerVisionRecipes library  based on fastai, [notebooks](https://github.com/microsoft/computervision-recipes/tree/master/scenarios/segmentation) y el Blog tds on [ComputerVisionRecipes for Pytorch](https://medium.com/pytorch/pytorch-computer-vision-library-for-experts-and-beginners-84b9157584e5)\n",
        "* github on NNs,autoencoders several frameworks [NNs-basics](https://github.com/scofield7419/basic_NNs_in_frameworks)\n",
        "* [Hands-On Guide to Implement ResNet50 in PyTorch with TPU](https://analyticsindiamag.com/hands-on-guide-to-implement-resnet50-in-pytorch-with-tpu/).\n",
        "\n",
        "\n",
        "##clustering \n",
        "*  Summary of standard non-CNN-based techiques with examples of SKlearn[machine-learning-masteryblog](https://machinelearningmastery.com/clustering-algorithms-with-python/)\n",
        "* [Grand-tour with fashion mnist](https://distill.pub/2020/grand-tour/)\n",
        "###(some useful repos)\n",
        "* [DEC ](https://github.com/vlukiyanov/pt-dec)\n",
        "* [DCC](https://github.com/shahsohil/DCC)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzYyN7dlh6bb",
        "colab_type": "text"
      },
      "source": [
        "#Some Important Support Libraries for ML/DL \n",
        "\n",
        "## Auto-ML\n",
        "\n",
        "* [Auto-pytorch](https://github.com/automl/Auto-PyTorch): utomatic architecture search and hyperparameter optimization for PyTorch by Freibug group. \n",
        "* [Adanet-pytorch](https://github.com/baldvaritesh/pytorch-adanet): Adaptive Structural Leaning for ANN.\n",
        "* [Deep-n-cheap2020 pytorch](https://www.groundai.com/project/deep-n-cheap-an-automated-search-framework-for-low-complexity-deep-learning/).\n",
        "[github-repo](https://github.com/souryadey/deep-n-cheap) and arxiv [DnC-paper](https://arxiv.org/abs/2004.00974v2.pdf). Includes penalty for training time per epoch $t_{tr}$\n",
        "\n",
        "* [Auto-Gluon pytorch](https://autogluon.mxnet.io/tutorials/torch/hpo.html) and [git-repo](https://github.com/awslabs/autogluon) with an Interesting introductory blogs: [here a general overview in tds](https://towardsdatascience.com/autogluon-deep-learning-automl-5cdb4e2388ec) and [here a medium entry for image data](https://medium.com/@zhanghang0704/image-classification-on-kaggle-using-autogluon-fc896e74d7e8) and [here a aws blog entry for tabular data](https://aws.amazon.com/es/blogs/opensource/machine-learning-with-autogluon-an-open-source-automl-library/)\n",
        "\n",
        "* [Featuretools](https://github.com/FeatureLabs/featuretools): An open source python library for automated feature engineering.\n",
        " \n",
        "\n",
        "##Explainability libraries\n",
        "* [Shap](https://github.com/slundberg/shap): SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions.\n",
        "* [Lime](https://github.com/marcotcr/lime): This project is about explaining what machine learning classifiers (or models) are doing. At the moment, we support explaining individual predictions for text classifiers or classifiers that act on tables (numpy arrays of numerical or categorical data) or images, with a package called lime (short for local interpretable model-agnostic explanations).\n",
        "\n",
        "## Visualization libraries\n",
        "\n",
        "* [Qgrid](https://qgrid.readthedocs.io/en/latest/): visually explore dataframes in notebooks[=>git-repo](https://github.com/quantopian/qgrid)\n",
        ">\n",
        "```python\n",
        "pip install qgrid\n",
        "jupyter nbextension enable --py --sys-prefix qgrid\n",
        "# only required if you have not enabled the ipywidgets nbextension yet\n",
        "jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
        "```\n",
        "* [Tensorboard pytorch](https://pytorch.org/docs/stable/tensorboard.html) and [tutorial for beginners](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html): Visualize models, data, results.\n",
        "\n",
        "* [Netron](https://github.com/lutzroeder/netron)\n",
        "\n",
        "## framework Translators/ NN fast-builders\n",
        "* [Hummingbird](https://github.com/microsoft/hummingbird) by microsoft (June 2020): Easy-to-use translator into pytorch, from lightgbm, XGboost,Sckit-learn. But for SKLearn RAPIDS seems more mature though.A [good deepnote notebook](https://beta.deepnote.com/article/supercharge-your-shallow-ml-models-with-hummingbird)\n",
        "\n",
        "* [NN_builder](https://github.com/p-christ/nn_builder): Build neural networks with less boilerplate code. Supports NN,CNN and RNN for pytorch.\n",
        "\n",
        "## other: libraries/database/sources\n",
        "\n",
        "* [DABL](https://dabl.github.io/dev/): Based on SKlearn, is a complete  DataScience pipeline package from preprocessing up to auto-ml. No boiler plate, quick autoplots of top features,lda, roc performance values, allow to  test several models etc. [more here ](https://dabl.github.io/dev/user_guide.html)\n",
        "\n",
        "* Professional Class Abstraction and encapsulations for a ML-pipelines [ML-abstracted.py](https://gist.githubusercontent.com/bhavsarpratik/9a7ae5fd9860ef64a84efa17fc18db27/raw/a9cd328dcb1de2788be3eed6590f8485d5044eeb/abstract.py)  \n",
        "\n",
        "* [Buffalo-Recommender](https://github.com/kakao/buffalo/tree/dev/examples): Buffalo is a fast and scalable production-ready open source project for recommender systems. Buffalo effectively utilizes system resources, enabling high performance even on low-spec machines. The implementation is optimized for CPU and SSD. Even so, it shows good performance with GPU accelerator, too. Buffalo, developed by Kakao, has been reliably used in production for various Kakao services.\n",
        "\n",
        "* [Tencent-ML](https://github.com/Tencent/tencent-ml-images): contains Resnet101- pretrained and the largest Image annotated dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7EQ35cQikMF",
        "colab_type": "text"
      },
      "source": [
        "# Quest for speed: Some libraries\n",
        "Its is fruitful to understand that there are several levels into the speed-quest landscape.  Whether a project requires involment at all levels is dependent on many factors like time,budget and difficulty, but some of the following entries (e.g. legate.numpy) might be straightforward  to include in every project workflow in order to speed-up the prototyping. The following classification, is a personal bottom-up and probably arbitrary point of view, and may change later on. \n",
        "\n",
        "\n",
        "* First, the Architecture numerical  operation and compiler level. \n",
        "* Second at basic library level, about the library capability to vectorize and then integrate that into architecture specifics. \n",
        "* Later, at the framework level (Tf,torch, and more intesively  recently SKlearn, reworking to optimize their underlying operations) but also subpackages refining initializations,learning rates, etc. \n",
        "* Finally, before they got popularity and get   a promotion into the previous level, there is a practitioner-research level, specially about training  (hyperparameter tuning but also network prunning)  with novel advances: more efficient, faster, network-type or task-type targeted. This type of model architecture simplification/reduction, is more focussed and likely to succeed than general AutoML and is already standard practice like Scikit-optimize. \n",
        "\n",
        "\n",
        "### **1. Architecture /compiler levels**\n",
        "* Intel Daal and MKL (more details on this later)\n",
        "\n",
        "* Intel Scalable dataframe compiler SDC(idem)\n",
        "\n",
        "* NVIDIA AdaptiveMixedPrecision (AMP) and TensorCores called [APEX lib](https://github.com/NVIDIA/apex): Usage intro in [=tds blog: Faster and Memory Efficient pytorch models](https://towardsdatascience.com/faster-and-memory-efficient-pytorch-models-using-amp-50fd3c8dd7fe) \n",
        "\n",
        "\n",
        "### **2. Library level: generic numpy/pandas library level (from scipy2020)**\n",
        "\n",
        "* legate numpy by NVIDIA: Seamless gpu numpy ``` import legate.numpy as np ```\n",
        "\n",
        "* [JAX](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html) (by Jakevdp): is NumPy on the CPU, GPU, and TPU, and JIT(which is XLA, see next section below), with great automatic differentiation for high-performance machine learning research. It is said they're autograd 2.0. This frontend seems at same level than pytorch. \n",
        "Some analysis compares PROS/CONS [here](https://sjmielke.com/jax-purify.htm) and benchmarks of performance versus pytorch at kaggle notebook [here](https://www.kaggle.com/grez911/performance-of-jax-vs-pytorch)\n",
        "* Cupy and Bohrium: Single gpu numpy...but not transparent!\n",
        "* RAPIDS: GPU supported syntax-like substitute for Pandas+SKlearn+Matplotlib\n",
        "* Modin: An identical(seamless)-pandas library (supports ray & dask) to allow distributed-transparent computation\n",
        "\n",
        "### **3. Practical-Framework (pytorch) level**\n",
        "\n",
        "* [Fast-ai package](https://docs.fast.ai/vision.html#vision) and [git-repo](https://github.com/fastai/fastai): The fastai library simplifies training fast and accurate neural nets using modern best practices. See the fastai website to get started. The library is based on research into deep learning best practices undertaken at fast.ai, and includes \"out of the box\" support for vision, text, tabular, and collab (collaborative filtering) models. For brief examples, see the examples folder; detailed examples are provided in the full documentation. For instance, here's how to train an MNIST model using resnet18 (from the vision example):\n",
        "\n",
        ">\n",
        "```\n",
        "from fastai.vision import *\n",
        "path = untar_data(MNIST_PATH)\n",
        "data = image_data_from_folder(path)\n",
        "learn = cnn_learner(data, models.resnet18, metrics=accuracy)\n",
        "learn.fit(1)\n",
        "```\n",
        "\n",
        "### **4. Training/hyperparam tuning level**\n",
        "\n",
        "* [Early-bird ICLR2020](https://github.com/RICE-EIC/Early-Bird-Tickets): This entry  is an improvement and **pytorch implementation** of lottery tickets hypothesis (Frankle & Carbin, 2019)  that shows that there exist winning tickets (small but critical subnetworks) for dense, randomly initialized networks, that can be trained alone to achieve comparable accuracies to the latter in a similar number of iterations.\n",
        "* [tutorial for HP-optimization](https://neptune.ai/blog/hyperparameter-tuning-on-any-python-script?utm_source=medium&utm_medium=crosspost&utm_campaign=blog-optuna-vs-hyperopt&utm_content=other-neptune-post): shows how to easily  decouple search params from code and wrap training and performance-evaluation into a function. A general introduction [this blog](https://towardsdatascience.com/hyperparameter-optimization-in-python-part-0-introduction-c4b66791614b)\n",
        "\n",
        "* [Optuna arxiv-July2019](https://arxiv.org/abs/1907.10902): framework in python [official Git-repo](https://github.com/optuna/optuna), and grear official web [with code examples](https://optuna.org/#code_examples). Its latest stable and ready-to-production version 1.0 was [Medium announced on Jan2020](https://medium.com/optuna/optuna-v1-86192cd09be5) though it was in the air since a [tds blog on Feb2019](https://towardsdatascience.com/how-to-make-your-model-awesome-with-optuna-b56d490368af). Here another [kaggle notebook tutorial](https://www.kaggle.com/corochann/optuna-tutorial-for-hyperparameter-optimization) \n",
        "\n",
        "\n",
        "* [Hyperopt](https://github.com/hyperopt/hyperopt):back before 2018 and currently upgraded, it has been the standard distibuted hpo on python. \n",
        "\n",
        "* **Optuna >= Hyperopt** TLDR, better doc, better documentation, faster and slightly better results. A tds blog [comparison with optuna](https://towardsdatascience.com/optuna-vs-hyperopt-which-hyperparameter-optimization-library-should-you-choose-ed8564618151)\n",
        "<p><img  height=\"300px\" src=\"https://miro.medium.com/max/700/1*CTQ0J1xNH--WV9JCC2mhiA.png\" align=\"left\" hspace=\"0px\" vspace=\"0px\">\n",
        "<img alt=\"recap\" height=\"300px\" src=\"https://miro.medium.com/max/661/0*-cxsR6Te90TUzb6g\" align=\"center\" hspace=\"0px\" vspace=\"0px\">\n",
        "</p> \n",
        "Comparison of HPO obtained by Optuna and an existing framework, both training a simplified AlexNet on the SVHN dataset. The error decreases significantly faster using Optuna. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByX9x_LNg6KZ",
        "colab_type": "text"
      },
      "source": [
        "# Selected Semantic-Segmentation sources (with pytorch)\n",
        "\n",
        "**Field summary(I)** by Meet Shah , Resident at Facebook AI.\n",
        "\n",
        "[Article-blog Semseg techniques](https://meetshah1995.github.io/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/semantic-segmentation-over-the-years.html)\n",
        "\n",
        "**Field Summary (II)** by D.Mwiti, Neptune.blog on march2020.\n",
        "\n",
        "[Image segmentation in 2020](https://neptune.ai/blog/image-segmentation-in-2020)\n",
        "\n",
        "**Review article/survey July2020**\n",
        "\n",
        "Evolution of Image Segmentation using Deep Convolutional Neural Network: A Survey [Sultana et al.=> sciencedirect](https://www.sciencedirect.com/science/article/abs/pii/S0950705120303464) or [at arxiv's](https://doi.org/10.1016/j.knosys.2020.106062)   \n",
        "\n",
        "**GENERIC Purpose Repo-listing: Only requirement is at least pytorch**\n",
        "* [ComputerVisionRecipes](https://github.com/microsoft/computervision-recipes/tree/master/scenarios/segmentation) : Based on Fast.ai library, with notebooks examples.\n",
        "* [PytorchCV](https://github.com/donnyyou/PyTorchCV)\n",
        "* [facebook research SS-architectures](https://github.com/facebookresearch/detectron2): Mask, detectron,detectro2.\n",
        "* [Pytorch Segmentation](https://github.com/nyoki-mtl/pytorch-segmentation):PyTorch implementation for semantic segmentation (DeepLabV3+, UNet, etc.)\n",
        "* [Easy to run/several NN:](https://github.com/charlesCXK/PyTorch_Semantic_Segmentation) \n",
        "Implement some models of RGB/RGBD semantic segmentation in PyTorch, easy to run. Such as FCN, RefineNet, PSPNet, RDFNet, 3DGNN, PointNet, DeepLab V3, DeepLab V3 plus, DenseASPP, FastFCN\n",
        "* [Semseg-architectures]( https://meetshah1995.github.io/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/semantic-segmentation-over-the-years.html) and [github-repo](https://github.com/meetshah1995/pytorch-semseg).\n",
        "* [Fasterseg](https://github.com/TAMU-VITA/FasterSeg):[ICLR 2020] \"FasterSeg: Searching for Faster Real-time Semantic Segmentation\" by Wuyang Chen, Xinyu Gong, Xianming Liu, Qian Zhang, Yuan Li, Zhangyang Wang\n",
        "*[Segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch): Segmentation models with pretrained backbones.\n",
        "*[Awesome SemSeg](https://github.com/Tramac/awesome-semantic-segmentation-pytorch): Semantic Segmentation on PyTorch (include FCN, PSPNet, Deeplabv3, Deeplabv3+, DANet, DenseASPP, BiSeNet, EncNet, DUNet, ICNet, ENet, OCNet, CCNet, PSANet, CGNet, ESPNet, LEDNet, DFANet).\n",
        "* [MIT SemSeg ADE20K](http://sceneparsing.csail.mit.edu/) with  [github-repo](https://github.com/CSAILVision/semantic-segmentation-pytorch):Pytorch implementation for Semantic Segmentation/Scene Parsing on MIT ADE20K dataset.\n",
        "* [Another SemSeg](https://github.com/zijundeng/pytorch-semantic-segmentation).\n",
        "* [Pytorch Unet](https://github.com/milesial/Pytorch-UNet):PyTorch implementation of the U-Net for image semantic segmentation with high quality images.\n",
        "* [PSPNet](https://github.com/kazuto1011/pspnet-pytorch)\n",
        "* [OpenCV deepN api: hands-on project](https://www.pyimagesearch.com/2018/09/03/semantic-segmentation-with-opencv-and-deep-learning/) and [blobfromimage-explained](https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDcwEZG1Xp-5",
        "colab_type": "text"
      },
      "source": [
        "# Brief Framework comparison and external references\n",
        "* Detailed post at edureka: [keras-vs-tensorflow-vs-pytorch](https://www.edureka.co/blog/keras-vs-tensorflow-vs-pytorch/)\n",
        "* Introduction to ML in [scikit-learn](https://www.edureka.co/blog/scikit-learn-machine-learning/)\n",
        "\n",
        "SciKit Learn is a general machine learning library, built on top of NumPy. It features a lot of machine learning algorithms such as support vector machines, random forests, as well as a lot of utilities for general pre- and postprocessing of data. It is not a neural network framework.\n",
        "\n",
        "PyTorch is a deep learning framework, consisting of\n",
        "\n",
        "    A vectorized math library similar to NumPy, but with GPU support and a lot of neural network related operations (such as softmax or various kinds of activations)\n",
        "    Autograd - an algorithm which can automatically calculate gradients of your functions, defined in terms of the basic operations\n",
        "    Gradient-based optimization routines for large scale optimization, dedicated to neural network optimization\n",
        "    Neural-network related utility functions\n",
        "\n",
        "Keras is a higher-level deep learning framework, which abstracts many details away, making code simpler and more concise than in PyTorch or TensorFlow, at the cost of limited hackability. It abstracts away the computation backend, which can be TensorFlow, Theano or CNTK. It does not support a PyTorch backend, but that's not something unfathomable - you can consider it a simplified and streamlined subset of the above.\n",
        "\n",
        "In short, if you are going with \"classic\", non-neural algorithms, neither PyTorch nor Keras will be useful for you. If you're doing deep learning, scikit-learn may still be useful for its utility part; aside from it you will need the actual deep learning framework, where you can choose between Keras and PyTorch but you're unlikely to use both at the same time. This is very subjective, but in my view, if you're working on a novel algorithm, you're more likely to go with PyTorch (or TensorFlow or some other lower-level framework) for flexibility. If you're adapting a known and tested algorithm to a new problem setting, you may want to go with Keras for its greater simplicity and lower entry level."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNibGjh1ider",
        "colab_type": "text"
      },
      "source": [
        "#About AutoML for pytorch: DnC workflow diagram\n",
        "![DnC Schematic](https://d3i71xaburhd42.cloudfront.net/dc1e802059137e908a363cb0f6063aa27257fef2/4-Figure1-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPkpJ4GhhlX1",
        "colab_type": "text"
      },
      "source": [
        "#AutoML-frameworks Comparison in 2020 \n",
        "Source: [Deep-n-Cheap github](https://github.com/souryadey/deep-n-cheap)\n",
        "\n",
        "**Remark $t_{tr}$** : penalty for training time per epoch \n",
        " \n",
        "![Comparison table1](https://d3i71xaburhd42.cloudfront.net/dc1e802059137e908a363cb0f6063aa27257fef2/13-Table1-1.png)\n",
        "\n",
        "![Comparison table2](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/dc1e802059137e908a363cb0f6063aa27257fef2/14-Table2-1.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFNmltlGDLyW",
        "colab_type": "text"
      },
      "source": [
        "# Some relevant info about the  Licenses Landscape/Zoo\n",
        "* [Wikipedia: Free software license ](https://en.wikipedia.org/wiki/Free-software_license)-\n",
        "* [Wikipedia: Comparison of free and open-source soft licenses ](https://en.wikipedia.org/wiki/Comparison_of_free_and_open-source_software_licences)\n",
        "\n",
        "\n",
        "* Article Source: [PloS Article](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002598) A Quick Guide to Software Licensing for the Scientist-Programmer,\n",
        "\n",
        " Citation: Morin A, Urban J, Sliz P (2012) A Quick Guide to Software Licensing for the Scientist-Programmer. PLOS Computational Biology 8(7): e1002598. https://doi.org/10.1371/journal.pcbi.1002598 \n",
        "\n",
        "* **Figure 2. Schematic representation of license directionality.**\n",
        "\n",
        "> In general, permissively licensed code is forward compatible with any other license type. However, only permissive licenses, such as the BSD and MIT, can feed into other permissive licenses. Restrictive licenses like the GPL are backward compatible with themselves and permissive licenses, but must adopt the restrictive license from then on. Proprietary licenses can incorporate upstream permissively licensed code, but by definition are incompatible with any other downstream license. Grey represents actions that are not permitted without negotiating a separate license agreement with the rights owner. \n",
        "![Diagramflow](https://journals.plos.org/ploscompbiol/article/figure/image?size=large&download=&id=10.1371/journal.pcbi.1002598.g002)\n",
        "* **Table 1. Summary of select attributes of cited licenses types.**\n",
        "![Scientific Programmer](https://journals.plos.org/ploscompbiol/article/figure/image?size=large&download=&id=10.1371/journal.pcbi.1002598.t001)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaFaCIvOi4Ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}