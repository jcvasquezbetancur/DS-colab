{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-start.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgXJxdKl0H7pZeSkpGa5VL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcvasquezbetancur/DS-colab/blob/master/pytorch_start_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzuRtfHF69is",
        "colab_type": "text"
      },
      "source": [
        "# Key sources Pytorch \n",
        "* [Introduction and comparison](https://blog.paperspace.com/why-use-pytorch-deep-learning-framework/): with a linear regresion notebook.\n",
        "\n",
        "* [60 min beginner video-tutorial](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) by pytorch.org\n",
        "\n",
        "* [Learning examples](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html) by pytorch.org\n",
        "* [Tensorboard tutorial](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)Visualize models, data, results.\n",
        "\n",
        "* [Fast-ai Vid-notebook course](https://course.fast.ai/videos/?lesson=7) \n",
        "\n",
        "* [Mnist example](https://github.com/pytorch/examples/blob/master/mnist/main.py) at official git-repo.\n",
        "* [VAE example](https://github.com/pytorch/examples/tree/master/vae) at official git-repo.\n",
        "\n",
        "* Hand-ons enabling [GPU-pytorch](https://towardsdatascience.com/speed-up-your-algorithms-part-1-pytorch-56d8a4ae7051) acceleration/configuration \n",
        "* ComputerVisionRecipes library  based on fastai, [notebooks](https://github.com/microsoft/computervision-recipes/tree/master/scenarios/segmentation) y el Blog tds on [ComputerVisionRecipes for Pytorch](https://medium.com/pytorch/pytorch-computer-vision-library-for-experts-and-beginners-84b9157584e5)\n",
        "* github on NNs,autoencoders several frameworks [NNs-basics](https://github.com/scofield7419/basic_NNs_in_frameworks)\n",
        "* [Featuretools](https://github.com/FeatureLabs/featuretools): An open source python library for automated feature engineering.\n",
        ". \n",
        "\n",
        "##clustering (repos)\n",
        "* [DEC ](https://github.com/vlukiyanov/pt-dec)\n",
        "* [DCC](https://github.com/shahsohil/DCC)\n",
        "\n",
        "## Auto-ML\n",
        "* [Auto-pytorch](https://github.com/automl/Auto-PyTorch): utomatic architecture search and hyperparameter optimization for PyTorch by Freibug group. \n",
        "* [Adanet-pytorch](https://github.com/baldvaritesh/pytorch-adanet): Adaptive Structural Leaning for ANN.\n",
        "* [Deep-n-cheap2020 pytorch](https://www.groundai.com/project/deep-n-cheap-an-automated-search-framework-for-low-complexity-deep-learning/).\n",
        "[github-repo](https://github.com/souryadey/deep-n-cheap) and arxiv [DnC-paper](https://arxiv.org/abs/2004.00974v2.pdf). Includes penalty for training time per epoch $t_{tr}$\n",
        "\n",
        "* [Auto-Gluon pytorch](https://autogluon.mxnet.io/tutorials/torch/hpo.html) and [git-repo](https://github.com/awslabs/autogluon) with an Interesting introductory blogs: [here a general overview in tds](https://towardsdatascience.com/autogluon-deep-learning-automl-5cdb4e2388ec) and [here a medium entry for image data](https://medium.com/@zhanghang0704/image-classification-on-kaggle-using-autogluon-fc896e74d7e8) and [here a aws blog entry for tabular data](https://aws.amazon.com/es/blogs/opensource/machine-learning-with-autogluon-an-open-source-automl-library/)\n",
        "\n",
        "##Explainability libraries\n",
        "* [Shap](https://github.com/slundberg/shap): SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions.\n",
        "* [Lime](https://github.com/marcotcr/lime): This project is about explaining what machine learning classifiers (or models) are doing. At the moment, we support explaining individual predictions for text classifiers or classifiers that act on tables (numpy arrays of numerical or categorical data) or images, with a package called lime (short for local interpretable model-agnostic explanations).\n",
        "\n",
        "## Visualization libraries\n",
        "\n",
        "* [Qgrid](https://qgrid.readthedocs.io/en/latest/): visually explore dataframes in notebooks[=>git-repo](https://github.com/quantopian/qgrid)\n",
        "> ```\n",
        "pip install qgrid\n",
        "jupyter nbextension enable --py --sys-prefix qgrid\n",
        "# only required if you have not enabled the ipywidgets nbextension yet\n",
        "jupyter nbextension enable --py --sys-prefix widgetsnbextension```\n",
        "```\n",
        "* [Tensorboard pytorch](https://pytorch.org/docs/stable/tensorboard.html) and [tutorial for beginners](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html): Visualize models, data, results.\n",
        "\n",
        "* [Netron](https://github.com/lutzroeder/netron)\n",
        "\n",
        "\n",
        "##other: libraries/database\n",
        "\n",
        "* AMP and TensorCores[apex lib](https://github.com/NVIDIA/apex) by NVIDIA: Usage intro in [=tds blog: Faster and Memory Efficient pytorch models](https://towardsdatascience.com/faster-and-memory-efficient-pytorch-models-using-amp-50fd3c8dd7fe) \n",
        "* [Fast-ai package](https://docs.fast.ai/vision.html#vision) and [git-repo](https://github.com/fastai/fastai): The fastai library simplifies training fast and accurate neural nets using modern best practices. See the fastai website to get started. The library is based on research into deep learning best practices undertaken at fast.ai, and includes \"out of the box\" support for vision, text, tabular, and collab (collaborative filtering) models. For brief examples, see the examples folder; detailed examples are provided in the full documentation. For instance, here's how to train an MNIST model using resnet18 (from the vision example):\n",
        "\n",
        ">\n",
        "```\n",
        "from fastai.vision import *\n",
        "path = untar_data(MNIST_PATH)\n",
        "data = image_data_from_folder(path)\n",
        "learn = cnn_learner(data, models.resnet18, metrics=accuracy)\n",
        "learn.fit(1)\n",
        "```\n",
        "* [Hummingbird](https://github.com/microsoft/hummingbird) by microsoft: Easy-to-use translator into pytorch, from lightgbm, XGboost,Sckit-learn y otros.\n",
        "* Professional Class Abstraction an encapsulations for a ML-pipeline [ML-abstracted.py](https://gist.githubusercontent.com/bhavsarpratik/9a7ae5fd9860ef64a84efa17fc18db27/raw/a9cd328dcb1de2788be3eed6590f8485d5044eeb/abstract.py)  \n",
        "* [Buffalo-Recommender](https://github.com/kakao/buffalo/tree/dev/examples): Buffalo is a fast and scalable production-ready open source project for recommender systems. Buffalo effectively utilizes system resources, enabling high performance even on low-spec machines. The implementation is optimized for CPU and SSD. Even so, it shows good performance with GPU accelerator, too. Buffalo, developed by Kakao, has been reliably used in production for various Kakao services.\n",
        "\n",
        "* [Tencent-ML](https://github.com/Tencent/tencent-ml-images): contains Resnet101- pretrained and the largest Image annotated dataset.\n",
        "## Jupyter Extensions\n",
        "* [GeoNotebook](https://github.com/OpenGeoscience/geonotebook) by Kitware&NASA\n",
        "\n",
        "* [ArcGIS-python-API](https://github.com/Esri/arcgis-python-api/tree/master/samples/04_gis_analysts_data_scientists)\n",
        "\n",
        "## All Semantic segmentation (with pytorch)\n",
        "\n",
        "**Field summary** by Meet Shah , Resident at Facebook AI.\n",
        "[Article-blog Semseg techniques](https://meetshah1995.github.io/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/semantic-segmentation-over-the-years.html)\n",
        "\n",
        "**Repo-listing: Only requirement is at least pytorch**\n",
        "* [ComputerVisionRecipes](https://github.com/microsoft/computervision-recipes/tree/master/scenarios/segmentation) : Based on Fast.ai library, with notebooks examples.\n",
        "* [TorchSAT](https://torchsat.readthedocs.io) and [github-repo](https://github.com/sshuair/torchsat): an open-source deep learning framework for satellite imagery analysis based on PyTorch.\n",
        "* [Raster Vision](https://docs.rastervision.io) and [github-repo](https://github.com/azavea/raster-vision): An open source framework for deep learning on satellite and aerial imagery.\n",
        "* [facebook research SS-architectures](https://github.com/facebookresearch/detectron2): Mask, detectron,detectro2.\n",
        "* [Pytorch Segmentation](https://github.com/nyoki-mtl/pytorch-segmentation):PyTorch implementation for semantic segmentation (DeepLabV3+, UNet, etc.)\n",
        "* [Easy to run/several NN:](https://github.com/charlesCXK/PyTorch_Semantic_Segmentation) \n",
        "Implement some models of RGB/RGBD semantic segmentation in PyTorch, easy to run. Such as FCN, RefineNet, PSPNet, RDFNet, 3DGNN, PointNet, DeepLab V3, DeepLab V3 plus, DenseASPP, FastFCN\n",
        "* [Semseg-architectures]( https://meetshah1995.github.io/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/semantic-segmentation-over-the-years.html) and [github-repo](https://github.com/meetshah1995/pytorch-semseg).\n",
        "* [Fasterseg](https://github.com/TAMU-VITA/FasterSeg):[ICLR 2020] \"FasterSeg: Searching for Faster Real-time Semantic Segmentation\" by Wuyang Chen, Xinyu Gong, Xianming Liu, Qian Zhang, Yuan Li, Zhangyang Wang\n",
        "*[Segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch): Segmentation models with pretrained backbones.\n",
        "*[Awesome SemSeg](https://github.com/Tramac/awesome-semantic-segmentation-pytorch): Semantic Segmentation on PyTorch (include FCN, PSPNet, Deeplabv3, Deeplabv3+, DANet, DenseASPP, BiSeNet, EncNet, DUNet, ICNet, ENet, OCNet, CCNet, PSANet, CGNet, ESPNet, LEDNet, DFANet).\n",
        "* [MIT SemSeg ADE20K](http://sceneparsing.csail.mit.edu/) with  [github-repo](https://github.com/CSAILVision/semantic-segmentation-pytorch):Pytorch implementation for Semantic Segmentation/Scene Parsing on MIT ADE20K dataset.\n",
        "* [Another SemSeg](https://github.com/zijundeng/pytorch-semantic-segmentation).\n",
        "* [Pytorch Unet](https://github.com/milesial/Pytorch-UNet):PyTorch implementation of the U-Net for image semantic segmentation with high quality images.\n",
        "\n",
        "* [PSPNet](https://github.com/kazuto1011/pspnet-pytorch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFNmltlGDLyW",
        "colab_type": "text"
      },
      "source": [
        "# Licenses Landscape/Zoo\n",
        "* [Wikipedia: Free software license ](https://en.wikipedia.org/wiki/Free-software_license)-\n",
        "* [Wikipedia: Comparison of free and open-source soft licenses ](https://en.wikipedia.org/wiki/Comparison_of_free_and_open-source_software_licences)\n",
        "\n",
        "\n",
        "* Article Source: [PloS Article](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002598) A Quick Guide to Software Licensing for the Scientist-Programmer,\n",
        "\n",
        " Citation: Morin A, Urban J, Sliz P (2012) A Quick Guide to Software Licensing for the Scientist-Programmer. PLOS Computational Biology 8(7): e1002598. https://doi.org/10.1371/journal.pcbi.1002598 \n",
        "\n",
        "* **Figure 2. Schematic representation of license directionality.**\n",
        "\n",
        "> In general, permissively licensed code is forward compatible with any other license type. However, only permissive licenses, such as the BSD and MIT, can feed into other permissive licenses. Restrictive licenses like the GPL are backward compatible with themselves and permissive licenses, but must adopt the restrictive license from then on. Proprietary licenses can incorporate upstream permissively licensed code, but by definition are incompatible with any other downstream license. Grey represents actions that are not permitted without negotiating a separate license agreement with the rights owner. \n",
        "![Diagramflow](https://journals.plos.org/ploscompbiol/article/figure/image?size=large&download=&id=10.1371/journal.pcbi.1002598.g002)\n",
        "* **Table 1. Summary of select attributes of cited licenses types.**\n",
        "![Scientific Programmer](https://journals.plos.org/ploscompbiol/article/figure/image?size=large&download=&id=10.1371/journal.pcbi.1002598.t001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDcwEZG1Xp-5",
        "colab_type": "text"
      },
      "source": [
        "# Framework comparison\n",
        "* Detailed post at edureka: [keras-vs-tensorflow-vs-pytorch](https://www.edureka.co/blog/keras-vs-tensorflow-vs-pytorch/)\n",
        "* Introduction to ML in [scikit-learn](https://www.edureka.co/blog/scikit-learn-machine-learning/)\n",
        "\n",
        "SciKit Learn is a general machine learning library, built on top of NumPy. It features a lot of machine learning algorithms such as support vector machines, random forests, as well as a lot of utilities for general pre- and postprocessing of data. It is not a neural network framework.\n",
        "\n",
        "PyTorch is a deep learning framework, consisting of\n",
        "\n",
        "    A vectorized math library similar to NumPy, but with GPU support and a lot of neural network related operations (such as softmax or various kinds of activations)\n",
        "    Autograd - an algorithm which can automatically calculate gradients of your functions, defined in terms of the basic operations\n",
        "    Gradient-based optimization routines for large scale optimization, dedicated to neural network optimization\n",
        "    Neural-network related utility functions\n",
        "\n",
        "Keras is a higher-level deep learning framework, which abstracts many details away, making code simpler and more concise than in PyTorch or TensorFlow, at the cost of limited hackability. It abstracts away the computation backend, which can be TensorFlow, Theano or CNTK. It does not support a PyTorch backend, but that's not something unfathomable - you can consider it a simplified and streamlined subset of the above.\n",
        "\n",
        "In short, if you are going with \"classic\", non-neural algorithms, neither PyTorch nor Keras will be useful for you. If you're doing deep learning, scikit-learn may still be useful for its utility part; aside from it you will need the actual deep learning framework, where you can choose between Keras and PyTorch but you're unlikely to use both at the same time. This is very subjective, but in my view, if you're working on a novel algorithm, you're more likely to go with PyTorch (or TensorFlow or some other lower-level framework) for flexibility. If you're adapting a known and tested algorithm to a new problem setting, you may want to go with Keras for its greater simplicity and lower entry level."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNibGjh1ider",
        "colab_type": "text"
      },
      "source": [
        "#AutoML- DnC workflow diagram\n",
        "![DnC Schematic](https://d3i71xaburhd42.cloudfront.net/dc1e802059137e908a363cb0f6063aa27257fef2/4-Figure1-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPkpJ4GhhlX1",
        "colab_type": "text"
      },
      "source": [
        "#AutoML- Comparison \n",
        "Source: [Deep-n-Cheap github](https://github.com/souryadey/deep-n-cheap)\n",
        "\n",
        "**Remark $t_{tr}$** : penalty for training time per epoch \n",
        " \n",
        "![Comparison table1](https://d3i71xaburhd42.cloudfront.net/dc1e802059137e908a363cb0f6063aa27257fef2/13-Table1-1.png)\n",
        "\n",
        "![Comparison table2](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/dc1e802059137e908a363cb0f6063aa27257fef2/14-Table2-1.png)\n"
      ]
    }
  ]
}